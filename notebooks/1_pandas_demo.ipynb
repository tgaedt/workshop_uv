{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8936e4d",
   "metadata": {},
   "source": [
    "# Demonstration of some Pandas capabilities using a famous concrete dataset\n",
    "\n",
    "First, we are going to import some necessary libraries and to load the famous concrete dataset published by Yeh et al.\n",
    "To save typing, we have created a tinyurl `tunyurl.com/icccm1` which contains a link to a `xls` file containing the dataset.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tgaedt/workshop_uv/blob/main/notebooks/1_pandas_demo.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = \"https://tinyurl.com/icccm1\"\n",
    "df = pd.read_excel(url) \n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a3f31",
   "metadata": {},
   "source": [
    "We note that the column names are very long and contain some special characers. Therefore, we will manually rename the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"cement\", \"bfs\", \"flyash\", \"water\", \"sp\", \"agg_coarse\", \"agg_fine\", \"age\", \"strength\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the dataframe\n",
    "df_length = len(df)\n",
    "df_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c227312",
   "metadata": {},
   "source": [
    "## Different ways to select a column in Pandas\n",
    "We now demonstrate how to select a column with Pandas. Note that the type of a column is a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.cement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5188bc",
   "metadata": {},
   "source": [
    "A specific column, here the column containing the amount of cement can be selected using a dot notation like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cement.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ee4ff",
   "metadata": {},
   "source": [
    "Alternatively a notation with square brackets is also possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cement\"].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003b4c3",
   "metadata": {},
   "source": [
    "It is also possible to use in indexed location based access. The `:` means that all rows are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef455972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0078b",
   "metadata": {},
   "source": [
    "A name based selection is also possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col4 = df.loc[:,\"cement\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07680d4",
   "metadata": {},
   "source": [
    "## Create a new column - calculate the w/c value\n",
    "\n",
    "A new column can be created with a simple assignment like `df[\"new_col_name\"]`. \n",
    "Alternatively the methods `assign()` or `insert()` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"wc\"] = df[\"water\"] / (df[\"cement\"] + df[\"bfs\"] + df[\"flyash\"])\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cec429",
   "metadata": {},
   "source": [
    "A column can be deleted with the method `drop()`, using the parameter `inplace = True` enables to leave out the assignment `df = df.drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"wc\"], inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23b639",
   "metadata": {},
   "source": [
    "Next, we show the assign and insert methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce21d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(wc = df[\"water\"] / (df[\"cement\"] + df[\"bfs\"] + df[\"flyash\"]))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab71fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the column again\n",
    "df.drop(columns=[\"wc\"], inplace=True)\n",
    "\n",
    "# the insert method allows to specify the column index\n",
    "df.insert(4, \"wc\", df[\"water\"] / (df[\"cement\"] + df[\"bfs\"] + df[\"flyash\"]))\n",
    "df.iloc[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209a950",
   "metadata": {},
   "source": [
    "It is probably a good idea to round the water-to-cement ratio after two decimal positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better to round off after the second decimal\n",
    "df[\"wc\"] = df[\"wc\"].round(2)\n",
    "df.iloc[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb7c3f",
   "metadata": {},
   "source": [
    "## Data types\n",
    "Currently, the dataframe only has float and int as datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f5ba3",
   "metadata": {},
   "source": [
    "We are now going to create a new column which contains entries of type `boolean`. Therefore, we are going to chose an arbitrary criterium to check. Here, we are going to evaluate whether the w/c value is higher than 0.42. We will name the column `wc_high`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0428d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(5, \"wc_high\", df[\"wc\"] > 0.42)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f87114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d775d8",
   "metadata": {},
   "source": [
    "## Calculating overview metrics of the dataset\n",
    "Because `True` will evaluate to 1, we can easily count the number of concretes with a w/c ratio of larger than 0.42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb82ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count high wc instances\n",
    "nr_high = df.wc_high.sum()\n",
    "\n",
    "nr_high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4b3a1",
   "metadata": {},
   "source": [
    "Of course, this can be also summarized in one line for quick counting. No need to create a new column. Let's count the concretes with more than 100 kg of slag in the mix design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"bfs\"] > 100).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187ba48",
   "metadata": {},
   "source": [
    "It is also easy and straightforward to obtrain the mean values of all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c96a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2a0d7",
   "metadata": {},
   "source": [
    "Pandas has a nice method (`desribe()`) for getting a quick overview about the data properties in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b14ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7383c",
   "metadata": {},
   "source": [
    "## Filtering a dataset\n",
    "Very often, you need to filter a dataframe by one or more criteria. This can be achieved in differnt ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e356fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter operations\n",
    "df_high = df.query(\"wc_high > 0.42\")\n",
    "df_high.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba032e",
   "metadata": {},
   "source": [
    "One thing we has irritated me many, many times is the concept of a **view** in Pandas. The `df.query(\"wc_high > 0.42\")` method does not necessarily creates a filtered copy of the original dataframe, i.e. a **new**, independent dataframe to the variable `df_high`. You can get a `SettingWithCopyWarning`. For details see https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2badf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high[\"new_var\"] = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a583a",
   "metadata": {},
   "source": [
    "The warning can be avoided by calling the `copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e481f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = df.query(\"wc_high > 0.42\").copy()\n",
    "df_high[\"new_var\"] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa5dc0",
   "metadata": {},
   "source": [
    "Another method to filter dataframes is to create a filter mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df[\"wc\"] > 0.48) & (df[\"bfs\"] < 50)\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369f28e",
   "metadata": {},
   "source": [
    "Now the mask can be applied to a dataframe to create a filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73571f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e402ad",
   "metadata": {},
   "source": [
    "## Joining datasets\n",
    "Often, two datasets need to be joined. To do a join operation, a common key is necessary for both dataframes. We can not go into details here but would like to illustrate this point using simple, artifical example. \n",
    "\n",
    "First, we need to create a key in the existing concrete dataset. In our case, suitable keys are often the names or codes of the individual experiment. Here, we will create a new column with strings `concrete_mix_1` etc. To create this list, we will use the index values of the original dataframe as numbers. \n",
    "Note that every dataframe object in pandas has an index. In the current case the index is just a list of numbers called `RangeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de429d68",
   "metadata": {},
   "source": [
    "We can loop through the index and get the inidividual numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in df.index[:6]:\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f4b4b",
   "metadata": {},
   "source": [
    "A more concise way to do this in Python is the use of a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802265b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[number for number in df.index[:6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd70d52",
   "metadata": {},
   "source": [
    "We can now combine a list comprehension which loops through all values in the index with a string **concrete_mix_**. Note that we need to transform the number from the index into a string object, i.e., we need to use `str(i)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\"concrete_mix_\" + str(i) for i in df.index.values]\n",
    "df[\"exp_code\"] = exp_names\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb91aea",
   "metadata": {},
   "source": [
    "We will now create a second dataframe which also contains a column with the strings **concrete_mix_** and some random values in a second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data = np.random.randint(0, 300, len(df)) \n",
    "df2 = pd.DataFrame({\"exp_code\":exp_names, \"new_parameter\": additional_data})\n",
    "\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c60887",
   "metadata": {},
   "source": [
    "Now the two dataframes `df` and `df2` can easily be joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join by index\n",
    "df_joined = pd.merge(df, df2, on=\"exp_code\")\n",
    "\n",
    "df_joined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236598f",
   "metadata": {},
   "source": [
    "## Visualization and exploratory data analysis\n",
    "The exploratory data analysis of a dataset is very important in understanding the relations between the parameters (i.e., the columns). For the concrete dataset we have 1030 compressive strength tests. We already know that the compressive strength of a concrete depends on the w/c value, the curing duration, and the cement content. \n",
    "\n",
    "We begin by exploring the relation between w/c ratio and strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"wc\"], df[\"strength\"])\n",
    "ax.set_xlabel(\"w/c\")\n",
    "ax.set_ylabel(\"Strength / MPa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06512e45",
   "metadata": {},
   "source": [
    "There is a clear downward trend in the data with increasing w/c values. The most important parameter to take into account now is the curing age of the concrete. We will filter the dataset to include 3, 7, and 28 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df.query(\"age in [3, 7, 28]\").groupby(\"age\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(group[\"wc\"], group[\"strength\"])\n",
    "    ax.set_title(f\"Age {name} days\")\n",
    "    ax.set_xlabel(\"w/c\")\n",
    "    ax.set_ylabel(\"Strength / MPa\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4899f3",
   "metadata": {},
   "source": [
    "## Subplots\n",
    "It would be nice to create a diagram with subplots so that the differences are far more easy to distinguish. This can be done in matplotlib using subplots. Here we are creating 1 row and 3 columns of subplots.\n",
    "\n",
    "Next we need to loop through the filtered and grouped data and simultaneously through the list containing the axes objects for the individual subplots. This can be achieved with the `zip` command in python. Because the `groupby` method returns two objects, we need to use brackets with the declaration of the loop. The parameter `observed = True` is necessary to suppress a deprecation warning. Feel free to ignore this at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82114ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, layout=\"tight\", figsize=(9,4))\n",
    "\n",
    "for (name, group), ax in zip(df.query(\"age in [3, 7, 28]\").groupby(\"age\", observed=True), axs.flatten()):\n",
    "    ax.scatter(group[\"wc\"], group[\"strength\"], s=4)\n",
    "    ax.set_title(f\" Age {name} days\")\n",
    "    ax.set_xlabel(\"w/c\")\n",
    "    ax.set_ylim(0,90)\n",
    "axs[0].set_ylabel(\"Strength / MPa\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a141b",
   "metadata": {},
   "source": [
    "## Fast and simple correlation matrix using seaborn\n",
    "\n",
    "First, we will show how to get all correlation coefficents between the columns quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f781eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.select_dtypes(include=[\"number\"]).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf57ba1",
   "metadata": {},
   "source": [
    "Next, we will leverage a plotting library which builds on matplotlib and makes some plotting objectives much easier to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fc374",
   "metadata": {},
   "source": [
    "## Fitting the data (grouped)\n",
    "\n",
    "One way to illustrate the true usefulness of Python is to demonstrate how easy it is to fit the data in a grouped fashion. We are going to use the method `curve_fit` from scipy to do this.\n",
    "\n",
    "First, we define an exponential function `exponential`\n",
    "\n",
    "$$\n",
    "\\sigma_c = c + a \\cdot \\exp(-b\\cdot w/c)\n",
    "$$\n",
    "\n",
    "As we want to group our dataset by the age and then apply a fit function, we define `fit_exponential` which returns both the fit parameters and the R2 value for the quality of the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# define function to fit\n",
    "def exponential(x, a, b):\n",
    "    return a * np.exp(-b*x)\n",
    "\n",
    "# define function which returns the best fit parameters as a pandas Series\n",
    "def fit_exponential(df, xcol=\"wc\", ycol=\"strength\"):\n",
    "    f = exponential\n",
    "    popt, pcov = curve_fit(f, df[xcol], df[ycol], maxfev=10000)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    y_actual = df[ycol]\n",
    "    y_predicted = f(df[xcol], *popt)\n",
    "    ss_res = np.sum((y_actual - y_predicted) ** 2)\n",
    "    ss_tot = np.sum((y_actual - np.mean(y_actual)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    out = {\"a\": popt[0], \"b\": popt[1], \"r_squared\": r_squared}\n",
    "    return pd.Series(out)\n",
    "\n",
    "fits = df.query(\"age in [3, 7, 28]\").groupby(\"age\").apply(lambda t: fit_exponential(t), include_groups=False)\n",
    "\n",
    "fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b6ca6",
   "metadata": {},
   "source": [
    "## Plot the fitted curves and the raw data\n",
    "It is very important to check the quality of the fits. We are going to plot the fits together with the fitted raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(df.wc.min(), df.wc.max(),100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for index, row in fits.iterrows():\n",
    "    y = exponential(x, row[\"a\"], row[\"b\"])\n",
    "    ax.plot(x,y)\n",
    "for name, group in df.query(\"age in [3,7,28] \").groupby(\"age\"):\n",
    "    ax.scatter(group[\"wc\"], group[\"strength\"], s=8, alpha =0.5, label=name)\n",
    "ax.set_xlim(0.22, 0.8)\n",
    "ax.set_ylim(0, 90)\n",
    "ax.set_xlabel(\"w/c\")\n",
    "ax.set_ylabel(\"$\\sigma_c$ / MPa\")\n",
    "plt.legend(title=\"Age / Days\")\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
